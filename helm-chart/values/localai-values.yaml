# LocalAI Values Configuration
fullnameOverride: "localai"

gateway:
  enabled: true
  hostname: "localai.example.com"
  class: "nginx"
  tls:
    enabled: true
autoscaling:
  enabled: false

serviceAccount:
  create: true
  annotations: {}
  name: ""
  automount: true

localai:
  enabled: true
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8080
  models:
    - name: mistral
      path: models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
      parameters:
        template: mistral
        context_size: 8192
        f16: true
        gpu_layers: 50
        threads: 8
  persistence:
    enabled: true
    models:
      enabled: true
      storageClassName: "microk8s-hostpath"
      size: 10Gi
      accessMode: ReadWriteOnce
  image:
    repository: localai/localai
    tag: latest
    pullPolicy: Always

initContainers:
  - name: model-downloader
    image: curlimages/curl
    command: ["/bin/sh", "-c"]
    args:
      - |
        curl -L -o /models/mistral-7b-instruct-v0.1.Q4_K_M.gguf https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf
    volumeMounts:
      - name: models
        mountPath: /models

replicaCount: 1

volumes:
  - name: models-config
    configMap:
      name: models-config

volumeMounts:
  - name: models-config
    mountPath: /models/models.yaml
    subPath: models.yaml
